{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "9a3c1a9b2abf68fe537e73b8532cf2e1ab6b2ef98fbfa1136e187e2e862bcae8"
    },
    "kernelspec": {
      "display_name": "Python 3.7.0 64-bit ('BT4012': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Paper Implementation",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaCWXvFmRpQe"
      },
      "source": [
        "# Initialize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PxuUcjNRbKm",
        "outputId": "f877f017-12dd-491d-edb9-478c061c6a81"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYTl13LjRWMK",
        "outputId": "adb2a580-0667-496b-e5a6-14c994e44158"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python import tf2\n",
        "if not tf2.enabled():\n",
        "    import tensorflow.compat.v2 as tf\n",
        "    tf.enable_v2_behavior()\n",
        "    assert tf2.enabled()\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential, Model, Input\n",
        "\n",
        "from tensorflow.keras.layers import Dense, InputLayer\n",
        "import tensorflow_probability as tfp\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "tfpl = tfp.layers\n",
        "tfd = tfp.distributions\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, roc_curve\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import os\n",
        "%matplotlib inline\n",
        "from imblearn.over_sampling import ADASYN\n",
        "import seaborn as sns\n",
        "from xgboost import XGBClassifier\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "random_state = 42\n",
        "print(tf.__version__)\n",
        "print(tfp.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n",
            "0.14.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwz5m_wBIB1r"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxUVX_LgICJ-"
      },
      "source": [
        "\n",
        "def find_best_threshold(true, pred_scores, metric = metrics.f1_score):\n",
        "    step = (max(pred_scores) - min(pred_scores)) /100\n",
        "    cur_threshold = 0\n",
        "    best_threshold = 0\n",
        "    best_score = 0\n",
        "    while cur_threshold < max(pred_scores) :\n",
        "        cur_score = metric(true, pred_scores > cur_threshold)\n",
        "        if cur_score > best_score:\n",
        "            best_score = cur_score\n",
        "            best_threshold = cur_threshold\n",
        "        cur_threshold += step\n",
        "    return best_threshold\n",
        "def get_res(true, pred_scores, threshold, name = \"\"):\n",
        "    metrics_dict = {\"F1\":lambda x, y : metrics.f1_score(x, y > threshold),\n",
        "               \"AUC\": metrics.roc_auc_score,\n",
        "               \"AUC PRC\": metrics.average_precision_score\n",
        "               }\n",
        "    res = pd.Series()\n",
        "    res.name = name\n",
        "    for name, metric in metrics_dict.items():\n",
        "        res[name] = metric(true, pred_scores)\n",
        "    return res"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3JJHPZJIP3J"
      },
      "source": [
        "def anomalyScores(originalDF, reducedDF):\n",
        "    loss = np.sum((np.array(originalDF)-np.array(reducedDF))**2, axis=1)\n",
        "    loss = pd.Series(data=loss,index=originalDF.index)\n",
        "    loss = (loss-np.min(loss))/(np.max(loss)-np.min(loss))\n",
        "    return loss\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
        "def plotResults(trueLabels, anomalyScores, returnPreds = False):\n",
        "    preds = pd.concat([trueLabels, anomalyScores], axis=1)\n",
        "    preds.columns = ['trueLabel', 'anomalyScore']\n",
        "    precision, recall, thresholds = \\\n",
        "        precision_recall_curve(preds['trueLabel'],preds['anomalyScore'])\n",
        "    average_precision = \\\n",
        "        average_precision_score(preds['trueLabel'],preds['anomalyScore'])\n",
        "\n",
        "    plt.step(recall, precision, color='k', alpha=0.7, where='post')\n",
        "    plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n",
        "\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlim([0.0, 1.0])\n",
        "\n",
        "    plt.title('Precision-Recall curve: Average Precision = \\\n",
        "    {0:0.2f}'.format(average_precision))\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(preds['trueLabel'], \\\n",
        "                                     preds['anomalyScore'])\n",
        "    areaUnderROC = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='r', lw=2, label='ROC curve')\n",
        "    plt.plot([0, 1], [0, 1], color='k', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic: \\\n",
        "    Area under the curve = {0:0.2f}'.format(areaUnderROC))\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    if returnPreds==True:\n",
        "        return preds"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCJwvYkSHmGd"
      },
      "source": [
        "### Results holders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-D0R8vxHl1z"
      },
      "source": [
        "class results_holder:\n",
        "    def __init__(self, train_true, val_true, train_val_true, test_true):\n",
        "        self.train_res = pd.DataFrame()\n",
        "        self.val_res = pd.DataFrame()\n",
        "        self.test_res = pd.DataFrame()\n",
        "        self.train_true = train_true\n",
        "        self.train_val_true = train_val_true\n",
        "        self.val_true = val_true\n",
        "        self.test_true = test_true\n",
        "    def add_results(self, train, val, train_val, test, name = \"\"):\n",
        "        train_threshold = find_best_threshold(self.train_true, train)\n",
        "        val_threshold = find_best_threshold(self.val_true, val)\n",
        "        train_val_threshold = find_best_threshold(self.train_val_true, train_val)\n",
        "        \n",
        "        train_res = get_res(self.train_true, train, train_threshold, name)\n",
        "        val_res = get_res(self.val_true, val, val_threshold, name)\n",
        "        # Threshold on train_val\n",
        "        test_res = get_res(self.test_true, test, train_val_threshold, name)\n",
        "\n",
        "        self.train_res = self.train_res.append(train_res)\n",
        "        self.val_res = self.val_res.append(val_res)\n",
        "        self.test_res = self.test_res.append(test_res)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEvUGQMoIFoZ"
      },
      "source": [
        "## Import and Process Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": false,
        "_kg_hide-output": true,
        "_uuid": "cbc89746d900392dbddef6a0906e0b4fefe88523",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SQsO-YfRWMN",
        "outputId": "4061b83b-0ce2-45bc-cd58-5b0a5143ff35"
      },
      "source": [
        "input_path = \"/gdrive/MyDrive/BT4012 Project\"\n",
        "raw = pd.read_csv(f\"{input_path}/creditcard.csv\").sample(100000, random_state = random_state)\n",
        "X_train, X_test, y_train, y_test = train_test_split(raw.drop(\"Class\", axis = 1), raw[\"Class\"], test_size=0.25, random_state = random_state)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state = random_state)\n",
        "[x.shape for x in [X_train, X_val, X_test, y_train, y_val, y_test]]\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(75000, 30), (12500, 30), (12500, 30), (75000,), (12500,), (12500,)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0-4UMdPVZcx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff2faeb6-621e-4f75-92d7-b2eb83d21c3a"
      },
      "source": [
        "time_to_hours = lambda x : x / 3600 % 24\n",
        "log_scale = lambda x : np.log(x+1) # Prevent inf\n",
        "\n",
        "def preprocessing(data):\n",
        "    data = data.copy()\n",
        "    data[\"Time\"] = data[\"Time\"].apply(time_to_hours)\n",
        "    data[\"Amount\"] = data[\"Amount\"].apply(log_scale)\n",
        "    return data\n",
        "X_train_cleaned = preprocessing(X_train)\n",
        "X_val_cleaned = preprocessing(X_val)\n",
        "X_test_cleaned = preprocessing(X_test)\n",
        "X_train_cleaned.shape, X_val_cleaned.shape, X_test_cleaned.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((75000, 30), (12500, 30), (12500, 30))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcER1edlKtW6",
        "outputId": "1e756007-e0a8-479c-f5b8-2d7aa4981a5f"
      },
      "source": [
        "X_train_val_cleaned = pd.concat([X_train_cleaned, X_val_cleaned], axis = 0)\n",
        "y_train_val = pd.concat([y_train, y_val], axis = 0)\n",
        "\n",
        "all_results = results_holder(y_train, y_val, y_train_val, y_test)\n",
        "\n",
        "X_train_val_cleaned.shape, y_train_val.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((87500, 30), (87500,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "dGNTgMn-ioem",
        "outputId": "8a749451-5c16-485e-d830-4f9787975c5f"
      },
      "source": [
        "X_train_cleaned.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>134495</th>\n",
              "      <td>22.453611</td>\n",
              "      <td>-1.472397</td>\n",
              "      <td>0.342064</td>\n",
              "      <td>1.475451</td>\n",
              "      <td>0.058871</td>\n",
              "      <td>1.154972</td>\n",
              "      <td>0.788022</td>\n",
              "      <td>0.548575</td>\n",
              "      <td>0.332188</td>\n",
              "      <td>-0.395896</td>\n",
              "      <td>-0.598640</td>\n",
              "      <td>0.728040</td>\n",
              "      <td>0.637057</td>\n",
              "      <td>0.248511</td>\n",
              "      <td>0.152280</td>\n",
              "      <td>1.460489</td>\n",
              "      <td>-1.051531</td>\n",
              "      <td>0.539399</td>\n",
              "      <td>-2.175693</td>\n",
              "      <td>-2.467226</td>\n",
              "      <td>-0.590383</td>\n",
              "      <td>0.125903</td>\n",
              "      <td>0.773880</td>\n",
              "      <td>0.520450</td>\n",
              "      <td>-0.656679</td>\n",
              "      <td>-0.295381</td>\n",
              "      <td>-0.509949</td>\n",
              "      <td>0.089405</td>\n",
              "      <td>0.016172</td>\n",
              "      <td>2.707383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238733</th>\n",
              "      <td>17.610278</td>\n",
              "      <td>-0.537673</td>\n",
              "      <td>1.305584</td>\n",
              "      <td>-0.216030</td>\n",
              "      <td>-0.362919</td>\n",
              "      <td>0.102158</td>\n",
              "      <td>-1.073609</td>\n",
              "      <td>0.913679</td>\n",
              "      <td>-0.052749</td>\n",
              "      <td>-0.384988</td>\n",
              "      <td>-0.617919</td>\n",
              "      <td>-0.877046</td>\n",
              "      <td>0.569788</td>\n",
              "      <td>1.042128</td>\n",
              "      <td>0.468495</td>\n",
              "      <td>0.423610</td>\n",
              "      <td>-0.337881</td>\n",
              "      <td>-0.360529</td>\n",
              "      <td>0.111845</td>\n",
              "      <td>0.081928</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>0.476727</td>\n",
              "      <td>1.357714</td>\n",
              "      <td>-0.163708</td>\n",
              "      <td>0.117701</td>\n",
              "      <td>-0.446789</td>\n",
              "      <td>-0.189386</td>\n",
              "      <td>-0.149430</td>\n",
              "      <td>0.142881</td>\n",
              "      <td>3.680595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69992</th>\n",
              "      <td>14.906389</td>\n",
              "      <td>1.204744</td>\n",
              "      <td>0.332036</td>\n",
              "      <td>0.419879</td>\n",
              "      <td>1.204284</td>\n",
              "      <td>-0.456784</td>\n",
              "      <td>-1.156401</td>\n",
              "      <td>0.222527</td>\n",
              "      <td>-0.244576</td>\n",
              "      <td>-0.009082</td>\n",
              "      <td>0.016706</td>\n",
              "      <td>-0.136917</td>\n",
              "      <td>0.185274</td>\n",
              "      <td>-0.267222</td>\n",
              "      <td>0.452310</td>\n",
              "      <td>0.919730</td>\n",
              "      <td>-0.035420</td>\n",
              "      <td>-0.295170</td>\n",
              "      <td>-0.230926</td>\n",
              "      <td>-0.495037</td>\n",
              "      <td>-0.150596</td>\n",
              "      <td>0.051702</td>\n",
              "      <td>0.165180</td>\n",
              "      <td>-0.063627</td>\n",
              "      <td>0.718796</td>\n",
              "      <td>0.633879</td>\n",
              "      <td>-0.348841</td>\n",
              "      <td>0.011193</td>\n",
              "      <td>0.024707</td>\n",
              "      <td>2.630449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282022</th>\n",
              "      <td>23.390278</td>\n",
              "      <td>-4.304655</td>\n",
              "      <td>0.556812</td>\n",
              "      <td>1.907029</td>\n",
              "      <td>5.124435</td>\n",
              "      <td>-0.237664</td>\n",
              "      <td>2.369248</td>\n",
              "      <td>-4.414476</td>\n",
              "      <td>-8.339140</td>\n",
              "      <td>-1.639420</td>\n",
              "      <td>0.075057</td>\n",
              "      <td>-1.480551</td>\n",
              "      <td>-0.117490</td>\n",
              "      <td>-0.452826</td>\n",
              "      <td>0.588899</td>\n",
              "      <td>1.178412</td>\n",
              "      <td>1.214333</td>\n",
              "      <td>0.320657</td>\n",
              "      <td>0.955402</td>\n",
              "      <td>0.763382</td>\n",
              "      <td>0.233238</td>\n",
              "      <td>-3.383596</td>\n",
              "      <td>2.031254</td>\n",
              "      <td>2.013425</td>\n",
              "      <td>0.012022</td>\n",
              "      <td>0.220624</td>\n",
              "      <td>0.639576</td>\n",
              "      <td>0.824547</td>\n",
              "      <td>-0.269609</td>\n",
              "      <td>2.257588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269030</th>\n",
              "      <td>21.416111</td>\n",
              "      <td>1.845828</td>\n",
              "      <td>0.359027</td>\n",
              "      <td>-1.222742</td>\n",
              "      <td>3.724936</td>\n",
              "      <td>0.694074</td>\n",
              "      <td>0.027421</td>\n",
              "      <td>0.403851</td>\n",
              "      <td>-0.034137</td>\n",
              "      <td>-0.852703</td>\n",
              "      <td>1.485295</td>\n",
              "      <td>-1.603370</td>\n",
              "      <td>-1.261210</td>\n",
              "      <td>-1.937668</td>\n",
              "      <td>0.765001</td>\n",
              "      <td>-0.734385</td>\n",
              "      <td>0.655008</td>\n",
              "      <td>-0.541928</td>\n",
              "      <td>-0.556410</td>\n",
              "      <td>-1.352393</td>\n",
              "      <td>-0.285169</td>\n",
              "      <td>-0.114363</td>\n",
              "      <td>-0.542256</td>\n",
              "      <td>0.207178</td>\n",
              "      <td>0.504820</td>\n",
              "      <td>-0.050089</td>\n",
              "      <td>-0.159089</td>\n",
              "      <td>-0.078525</td>\n",
              "      <td>-0.041816</td>\n",
              "      <td>4.152771</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Time        V1        V2  ...       V27       V28    Amount\n",
              "134495  22.453611 -1.472397  0.342064  ...  0.089405  0.016172  2.707383\n",
              "238733  17.610278 -0.537673  1.305584  ... -0.149430  0.142881  3.680595\n",
              "69992   14.906389  1.204744  0.332036  ...  0.011193  0.024707  2.630449\n",
              "282022  23.390278 -4.304655  0.556812  ...  0.824547 -0.269609  2.257588\n",
              "269030  21.416111  1.845828  0.359027  ... -0.078525 -0.041816  4.152771\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTQY8J2u2yKY"
      },
      "source": [
        "X_train_cleaned_0s = X_train_cleaned[y_train == 0]\n",
        "X_val_cleaned_0s = X_val_cleaned[y_val == 0]\n",
        "X_train_val_cleaned_0s = X_train_val_cleaned[y_train_val== 0]\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLGkjnGG6BTI"
      },
      "source": [
        "# x = X_train_cleaned\n",
        "# y = y_train\n",
        "\n",
        "# x_norm, x_fraud = x.values[y == 0], x.values[y == 1]\n",
        "\n",
        "# x_norm_sample = x_norm[np.random.randint(x_norm.shape[0], size=100000), :]\n",
        "# x_norm_train_sample, x_norm_val_sample = train_test_split(x_norm_sample, test_size=0.2, random_state = 42)\n",
        "\n",
        "# tf_train = tf.data.Dataset.from_tensor_slices((x_norm_train_sample, x_norm_train_sample)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE).shuffle(int(10e4))\n",
        "# tf_val = tf.data.Dataset.from_tensor_slices((x_norm_val_sample, x_norm_val_sample)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE).shuffle(int(10e4))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgjvMlFEvdbQ"
      },
      "source": [
        "# Principal Component Analysis (PCA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJZzSQJ-wNIx"
      },
      "source": [
        "References:\n",
        "https://www.oreilly.com/library/view/hands-on-unsupervised-learning/9781492035633/ch04.html\n",
        "\n",
        "Note: PCA has already been applied on the dataset before this. Applying PCA again is redundant, but the reference tutorial which uses the same dataset mentions that it is ok to apply PCA twice. We will just assume that the features given are the original features. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W7esWfDvkYa"
      },
      "source": [
        "n_components = 30\n",
        "\n",
        "pca = PCA(n_components=n_components, random_state=random_state)\n",
        "\n",
        "# Fit only on non-anomalies\n",
        "pca.fit(X_train_cleaned_0s)\n",
        "\n",
        "def get_PCA_anomaly_Scores(data, pca):\n",
        "    # Decomposition\n",
        "    data_PCA = pca.transform(data)\n",
        "    # Reconstruction \n",
        "    data_PCA_inverse = pca.inverse_transform(data_PCA)\n",
        "    data_PCA_inverse = pd.DataFrame(data=data_PCA_inverse, index=data.index)\n",
        "    return anomalyScores(data, data_PCA_inverse)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTg_7-Y5xSQc"
      },
      "source": [
        "X_train_PCA_scores = get_PCA_anomaly_Scores(X_train_cleaned, pca)\n",
        "X_val_PCA_scores = get_PCA_anomaly_Scores(X_val_cleaned, pca)\n",
        "pca.fit(X_train_val_cleaned_0s)\n",
        "X_train_val_PCA_scores = get_PCA_anomaly_Scores(X_train_val_cleaned, pca)\n",
        "X_test_PCA_scores = get_PCA_anomaly_Scores(X_test_cleaned, pca)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkHnF05ZO1kO",
        "outputId": "2b539600-2c08-43de-b59f-286882df9ad3"
      },
      "source": [
        "all_results.add_results(X_train_PCA_scores, X_val_PCA_scores, X_train_val_PCA_scores, X_test_PCA_scores, \"PCA\" )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8NvO4bqjPgPV",
        "outputId": "db54150a-5885-4251-c4cb-ecbca25ca3f8"
      },
      "source": [
        "all_results.train_res"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AUC</th>\n",
              "      <th>AUC PRC</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>0.947501</td>\n",
              "      <td>0.189318</td>\n",
              "      <td>0.352941</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          AUC   AUC PRC        F1\n",
              "PCA  0.947501  0.189318  0.352941"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MpR0y9NWQO4b",
        "outputId": "6a2a2e05-3d37-4445-a8e8-23b4dd235a88"
      },
      "source": [
        "all_results.val_res"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AUC</th>\n",
              "      <th>AUC PRC</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>0.955023</td>\n",
              "      <td>0.206501</td>\n",
              "      <td>0.45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          AUC   AUC PRC    F1\n",
              "PCA  0.955023  0.206501  0.45"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WZIj3tcFQQzE",
        "outputId": "77cace17-8f1a-448e-98a4-7e6292c6e1ff"
      },
      "source": [
        "all_results.test_res"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AUC</th>\n",
              "      <th>AUC PRC</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PCA</th>\n",
              "      <td>0.97345</td>\n",
              "      <td>0.171445</td>\n",
              "      <td>0.16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         AUC   AUC PRC    F1\n",
              "PCA  0.97345  0.171445  0.16"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1ufoXSsvfNM"
      },
      "source": [
        "# Kernel PCA (kPCA) (Untestable due to memory issues)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFiHI7pV1FW9"
      },
      "source": [
        "We were unable to test kernel PCA as we could not allocate enough memory for the process\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teiYwT7tx1lm"
      },
      "source": [
        "# from sklearn.decomposition import KernelPCA\n",
        "# n_components = 30\n",
        "\n",
        "# kpca = KernelPCA(kernel = \"rbf\", #gaussian kernel\n",
        "#                  n_components=n_components, \n",
        "#                  random_state=random_state, copy_X=False, fit_inverse_transform=True) \n",
        "\n",
        "# # Fit only on non-anomalies\n",
        "# kpca.fit(X_train_cleaned_0s)\n",
        "\n",
        "# # Decomposition\n",
        "# X_train_cleaned_kPCA = pd.DataFrame(data=X_train_cleaned, index=X_train.index)\n",
        "\n",
        "# # Reconstruction \n",
        "# X_train_cleaned_kPCA_inverse = pca.inverse_transform(X_train_cleaned_kPCA)\n",
        "# X_train_cleaned_kPCA_inverse = pd.DataFrame(data=X_train_cleaned_kPCA_inverse,\n",
        "#                                    index=X_train.index)\n",
        "\n",
        "# def get_kPCA_anomaly_Scores(data, kpca):\n",
        "#     # Decomposition\n",
        "#     data_cleaned_kPCA = pd.DataFrame(data=data, index=data.index)\n",
        "\n",
        "#     # Reconstruction \n",
        "#     data_cleaned_kPCA_inverse = kpca.inverse_transform(data_cleaned_kPCA)\n",
        "#     data_cleaned_kPCA_inverse = pd.DataFrame(data=data_cleaned_kPCA_inverse,\n",
        "#                                    index=data.index)\n",
        "\n",
        "#     return anomalyScores(data, data_cleaned_kPCA_inverse)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIrloS9d7rXY"
      },
      "source": [
        "# X_train_kPCA_scores = get_kPCA_anomaly_Scores(X_train_cleaned, kpca)\n",
        "# X_val_kPCA_scores = get_kPCA_anomaly_Scores(X_val_cleaned, kpca)\n",
        "# kpca.fit(X_train_val_cleaned_0s)\n",
        "# X_train_val_kPCA_scores = get_kPCA_anomaly_Scores(X_train_val_cleaned, kpca)\n",
        "# X_test_kPCA_scores = get_kPCA_anomaly_Scores(X_test_cleaned, kpca)\n",
        "\n",
        "# all_results.add_results(X_train_kPCA_scores, X_val_kPCA_scores, X_train_val_kPCA_scores, X_test_kPCA_scores, \"kPCA\" )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_y_cdFNPxzB"
      },
      "source": [
        "# all_results.train_res"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1y6oKR2Pz37"
      },
      "source": [
        "# all_results.val_res"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jSF_FbYP3qf"
      },
      "source": [
        "# all_results.test_res"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRDgKfbAaVY8"
      },
      "source": [
        "# AutoEncoder (AE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suYD4OCDEC5C"
      },
      "source": [
        "References: \n",
        "BT4012 Tutorial Codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_0Bmh_i1qoB",
        "outputId": "c64a20b6-dafd-4d55-f734-91ebea719f89"
      },
      "source": [
        "input_shape = 30\n",
        "encoding_dim  = 2\n",
        "intermediary_dims = [25, 20, 15, 10]\n",
        "batch_size = 128\n",
        "max_epochs = 1000\n",
        "activation = \"relu\"\n",
        "\n",
        "input_layer = Input(shape=(input_shape,))\n",
        "encoded = Dense(16, activation=activation)(input_layer)\n",
        "encoded = Dense(8, activation=activation)(encoded)\n",
        "encoded = Dense(4, activation=activation)(encoded)\n",
        "\n",
        "# bottleneck layer\n",
        "encoded = Dense(encoding_dim, activation=activation)(encoded)\n",
        "\n",
        "decoded = Dense(4, activation=activation)(encoded)\n",
        "decoded = Dense(8, activation=activation)(decoded)\n",
        "decoded = Dense(16, activation=activation)(decoded)\n",
        "decoded = Dense(input_shape)(decoded)\n",
        "\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "encoder = Model(input_layer, encoded)\n",
        "decoder_layer1, decoder_layer2, decoder_layer3, decoder_layer4 = \\\n",
        "        autoencoder.layers[-1], autoencoder.layers[-2], autoencoder.layers[-3], autoencoder.layers[-4]\n",
        "\n",
        "\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "# create the decoder model\n",
        "decoder = Model(encoded_input, decoder_layer1(decoder_layer2(decoder_layer3(decoder_layer4(encoded_input)))))\n",
        "\n",
        "\n",
        "autoencoder.compile(optimizer=tf.keras.optimizers.Nadam(), \n",
        "            loss=\"mse\")\n",
        "encoder.summary()\n",
        "decoder.summary()\n",
        "autoencoder.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 30)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                496       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 36        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 10        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 678\n",
            "Trainable params: 678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4)                 12        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 8)                 40        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                144       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 30)                510       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 706\n",
            "Trainable params: 706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 30)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                496       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 36        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 10        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4)                 12        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 8)                 40        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                144       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 30)                510       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,384\n",
            "Trainable params: 1,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV9xi2196XN3",
        "outputId": "50b78e38-d7ed-4ccc-d5cd-6556ab00370d"
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath='AE_train_bestmodel.h5', verbose=0, save_best_only=True)\n",
        "earlystopper = EarlyStopping(monitor='val_loss', mode='min', min_delta=0.005, patience=20, verbose=0, restore_best_weights=True)\n",
        "reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
        "hist = autoencoder.fit(X_train_cleaned_0s, X_train_cleaned_0s,\n",
        "               epochs=max_epochs,\n",
        "               shuffle=True,\n",
        "               verbose=1,\n",
        "               validation_data= (X_val_cleaned_0s, X_val_cleaned_0s),\n",
        "               callbacks=[checkpointer, earlystopper, reduceLR])\n",
        "\n",
        "autoencoder_train = autoencoder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "2340/2340 [==============================] - 21s 7ms/step - loss: 1.2512 - val_loss: 0.8851 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "2340/2340 [==============================] - 17s 7ms/step - loss: 0.8617 - val_loss: 0.8364 - lr: 0.0010\n",
            "Epoch 3/1000\n",
            "2340/2340 [==============================] - 17s 7ms/step - loss: 0.8246 - val_loss: 0.8011 - lr: 0.0010\n",
            "Epoch 4/1000\n",
            "2340/2340 [==============================] - 17s 7ms/step - loss: 0.8012 - val_loss: 0.7769 - lr: 0.0010\n",
            "Epoch 5/1000\n",
            "2340/2340 [==============================] - 17s 7ms/step - loss: 0.7786 - val_loss: 0.7585 - lr: 0.0010\n",
            "Epoch 6/1000\n",
            "2340/2340 [==============================] - 17s 7ms/step - loss: 0.7650 - val_loss: 0.7451 - lr: 0.0010\n",
            "Epoch 7/1000\n",
            "2340/2340 [==============================] - 17s 7ms/step - loss: 0.7556 - val_loss: 0.7424 - lr: 0.0010\n",
            "Epoch 8/1000\n",
            "2264/2340 [============================>.] - ETA: 0s - loss: 0.7533"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTm5vsHZV7Nm"
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath='AE_train_val_bestmodel.h5', verbose=0, save_best_only=True, monitor='loss')\n",
        "earlystopper = EarlyStopping(monitor='loss', mode='min', min_delta=0.005, patience=20, verbose=0, restore_best_weights=True)\n",
        "reduceLR = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=2, min_lr=0.0001)\n",
        "\n",
        "hist = autoencoder.fit(X_train_val_cleaned_0s, X_train_val_cleaned_0s,\n",
        "               epochs=max_epochs,\n",
        "               shuffle=True,\n",
        "               verbose=1,\n",
        "               callbacks=[checkpointer, earlystopper, reduceLR])\n",
        "\n",
        "autoencoder_train_val = autoencoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbJoW1JZRyjI"
      },
      "source": [
        "AE_X_train = autoencoder_train(X_train_cleaned.values)\n",
        "AE_X_val = autoencoder_train(X_val_cleaned.values)\n",
        "AE_X_train_val = autoencoder_train_val(X_train_val_cleaned.values)\n",
        "AE_X_test = autoencoder_train_val(X_test_cleaned.values)\n",
        "AE_train_scores = anomalyScores(X_train_cleaned, AE_X_train)\n",
        "AE_val_scores = anomalyScores(X_val_cleaned, AE_X_val)\n",
        "AE_train_val_scores = anomalyScores(X_train_val_cleaned, AE_X_train_val)\n",
        "AE_test_scores = anomalyScores(X_test_cleaned, AE_X_test)\n",
        "\n",
        "\n",
        "all_results.add_results(AE_train_scores, AE_val_scores, AE_train_val_scores, AE_test_scores, \"AE\" )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8evXrg-XJv9"
      },
      "source": [
        "all_results.train_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnKpBfXcXLT_"
      },
      "source": [
        "all_results.val_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZOyHHtjXNBZ"
      },
      "source": [
        "all_results.test_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUMLKrq3vYTP"
      },
      "source": [
        "# Variational AutoEncoder (VAE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3k8PRfv4Y3L"
      },
      "source": [
        "https://medium.com/tensorflow/variational-autoencoders-with-tensorflow-probability-layers-d06c658931b7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "bd005b66ce9d41d43f6ff07674ebe64e3ba15717",
        "id": "cm5N2qGtRWMS"
      },
      "source": [
        "def create_vae():\n",
        "    def dense_layers(sizes):\n",
        "        layers = Sequential([Dense(size, activation = \"relu\") for size in sizes])\n",
        "        return layers\n",
        "\n",
        "    input_shape =30\n",
        "    intermediary_dims = [25, 20, 15, 10]\n",
        "    latent_dim = 2\n",
        "\n",
        "    # prior = tfd.Independent(tfd.Normal(loc=tf.zeros(latent_dim), scale=1),\n",
        "    #                         reinterpreted_batch_ndims=1)\n",
        "\n",
        "    prior = tfd.MultivariateNormalDiag(\n",
        "            loc=tf.zeros([latent_dim]),\n",
        "            scale_identity_multiplier=1.0)\n",
        "\n",
        "    encoder = Sequential([\n",
        "        InputLayer(input_shape=input_shape, name='encoder_input'),\n",
        "        dense_layers(intermediary_dims),\n",
        "        Dense(tfpl.MultivariateNormalTriL.params_size(latent_dim), activation=None),\n",
        "        tfpl.MultivariateNormalTriL(latent_dim, activity_regularizer=tfpl.KLDivergenceRegularizer(prior)),\n",
        "    ], name='encoder')\n",
        "\n",
        "    # encoder.summary()\n",
        "    # plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n",
        "\n",
        "    decoder = Sequential([\n",
        "        InputLayer(input_shape=[latent_dim]),\n",
        "        dense_layers(reversed(intermediary_dims)),\n",
        "        Dense(tfpl.IndependentNormal.params_size(input_shape), activation=None),\n",
        "        tfpl.IndependentNormal(input_shape),\n",
        "    ], name='decoder')\n",
        "\n",
        "    # decoder.summary()\n",
        "    # plot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True)\n",
        "\n",
        "    vae = Model(inputs=encoder.inputs,\n",
        "                    outputs=decoder(encoder.outputs[0]),\n",
        "                    name='vae_mlp')\n",
        "\n",
        "    negloglik = lambda x, rv_x: -rv_x.log_prob(x)\n",
        "\n",
        "    vae.compile(optimizer=tf.keras.optimizers.Nadam(), \n",
        "                loss=negloglik)\n",
        "\n",
        "    # vae.summary()\n",
        "    # plot_model(vae,\n",
        "    #            to_file='vae_mlp.png',\n",
        "    #            show_shapes=True)\n",
        "\n",
        "    return encoder, decoder, vae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F1O-fKY7_-7"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "ss = StandardScaler()\n",
        "X_train_cleaned_0sss = ss.fit_transform(X_train_cleaned_0s)\n",
        "X_val_cleaned_0sss = ss.transform(X_val_cleaned_0s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "9a80a22488211ff67043b170218cc2489b158ef4",
        "id": "3KdnVJYrRWMU"
      },
      "source": [
        "batch_size = 128\n",
        "max_epochs = 1000\n",
        "tf_X_train_cleaned_0s = tf.data.Dataset.from_tensor_slices((X_train_cleaned_0s, X_train_cleaned_0s)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE).shuffle(int(10e4))\n",
        "tf_X_val_cleaned_0s = tf.data.Dataset.from_tensor_slices((X_val_cleaned_0s, X_val_cleaned_0s)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE).shuffle(int(10e4))\n",
        "\n",
        "train_vae_encoder, train_vae_decoder, train_vae = create_vae()\n",
        "checkpointer = ModelCheckpoint(filepath='vae_train_bestmodel.h5', verbose=0, save_best_only=True)\n",
        "earlystopper = EarlyStopping(monitor='val_loss', mode='min', min_delta=0.005, patience=5, verbose=0, restore_best_weights=True)\n",
        "reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
        "\n",
        "hist = train_vae.fit(tf_X_train_cleaned_0s,\n",
        "               epochs=max_epochs,\n",
        "               shuffle=True,\n",
        "               verbose=1,\n",
        "               validation_data= tf_X_val_cleaned_0s,\n",
        "               callbacks=[checkpointer, earlystopper, reduceLR])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d_XqqUiyUis"
      },
      "source": [
        "train_val_vae_encoder, train_val_vae_decoder, train_val_vae = create_vae()\n",
        "tf_X_train_val_cleaned_0s = tf.data.Dataset.from_tensor_slices((X_train_val_cleaned_0s, X_train_val_cleaned_0s)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE).shuffle(int(10e4))\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='vae_train_val_bestmodel.h5', verbose=0, save_best_only=True,monitor='loss')\n",
        "earlystopper = EarlyStopping(monitor='loss', mode='min', min_delta=0.005, patience=5, verbose=0, restore_best_weights=True)\n",
        "reduceLR = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=2, min_lr=0.0001)\n",
        "\n",
        "hist = train_val_vae.fit(tf_X_train_cleaned_0s,\n",
        "               epochs=max_epochs,\n",
        "               shuffle=True,\n",
        "               verbose=1,\n",
        "               callbacks=[checkpointer, earlystopper, reduceLR])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oevzng6kXvds"
      },
      "source": [
        "def reconstruction_log_prob(eval_sample, enc, dec, reconstruct_samples_n =100):\n",
        "    encoder_samples = enc(eval_sample)\n",
        "    return dec(encoder_samples).log_prob(eval_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVZ0pMLfnZ93"
      },
      "source": [
        "X_train_VAE_scores = reconstruction_log_prob(X_train_cleaned.values, train_vae_encoder, train_vae_decoder)\n",
        "X_val_VAE_scores = reconstruction_log_prob(X_val_cleaned.values, train_vae_encoder, train_vae_decoder)\n",
        "X_train_val_VAE_scores = reconstruction_log_prob(X_train_val_cleaned.values, train_val_vae_encoder, train_val_vae_decoder)\n",
        "X_test_VAE_scores = reconstruction_log_prob(X_test_cleaned.values, train_val_vae_encoder, train_val_vae_decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTLGNRaaSg-v"
      },
      "source": [
        "X_train_VAE_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wys5q7ngzcdg"
      },
      "source": [
        "all_results.add_results(-X_train_VAE_scores, -X_val_VAE_scores, -X_train_val_VAE_scores, -X_test_VAE_scores, \"VAE\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYdaztaH_b0p"
      },
      "source": [
        "all_results.train_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPuzAIazAMbB"
      },
      "source": [
        "all_results.val_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkPkhN_7AOtM"
      },
      "source": [
        "all_results.test_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qUS_cUBXF3a"
      },
      "source": [
        "np.round(all_results.val_res,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7omxQYko1Ea"
      },
      "source": [
        "ax = plt.hist([X_train_VAE_scores[y_train==0][:sum(y_train == 1)], X_train_VAE_scores[y_train==1]], 60)\n",
        "plt.title('reconstruction log probability')\n",
        "plt.ylabel('frequency')\n",
        "plt.xlabel(\"log p(x|x')\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxL1o1RcXs5e"
      },
      "source": [
        "AE_X_train = autoencoder_train(X_train_cleaned.values)\n",
        "AE_X_val = autoencoder_train(X_val_cleaned.values)\n",
        "AE_X_train_val = autoencoder_train_val(X_train_val_cleaned.values)\n",
        "AE_X_test = autoencoder_train_val(X_test_cleaned.values)\n",
        "\n",
        "\n",
        "AE_train_scores = anomalyScores(X_train_cleaned, AE_X_train)\n",
        "AE_val_scores = anomalyScores(X_val_cleaned, AE_X_val)\n",
        "AE_train_val_scores = anomalyScores(X_train_val_cleaned, AE_X_train_val)\n",
        "AE_test_scores = anomalyScores(X_test_cleaned, AE_X_test)\n",
        "\n",
        "\n",
        "all_results.add_results(AE_train_scores, AE_val_scores, AE_train_val_scores, AE_test_scores, \"AE\" )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyX3nAzo4Zqu"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1b1e6a513617455a80e6829cc84684486115e60a",
        "id": "LzNh2w3SRWMV"
      },
      "source": [
        "reconstruct_samples_n = 50\n",
        "\n",
        "def reconstruction_log_prob(eval_samples, reconstruct_samples_n):\n",
        "    encoder_out = encoder(eval_samples)\n",
        "    encoder_samples = encoder_out.sample(reconstruct_samples_n)\n",
        "    return np.mean(decoder(encoder_samples).log_prob(eval_samples), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EADIz0yroN24"
      },
      "source": [
        "X = X_train_cleaned.values\n",
        "Y = y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWJYamOcoWbz"
      },
      "source": [
        "X_train_cleaned.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0f3044fb313b74ee45e047b7ef0cbfe47ce008fe",
        "id": "opcBBJlpRWMX"
      },
      "source": [
        "x_log_prob = reconstruction_log_prob(X, reconstruct_samples_n)\n",
        "x_log_prob = np.log(-x_log_prob)/100\n",
        "ax = plt.hist([x_log_prob[Y==0][:500], x_log_prob[Y==1]], 60)\n",
        "plt.title('reconstruction log probability')\n",
        "plt.ylabel('frequency')\n",
        "plt.xlabel(\"log p(x|x')\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpAq2XR-uyRG"
      },
      "source": [
        "from sklearn import metrics\n",
        "metrics.roc_auc_score(Y, x_log_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "04a74edd42762aeb3f59bab9d603e9744ba2fb57",
        "id": "oobupdRWRWMY"
      },
      "source": [
        "fpr, tpr, thresh = roc_curve(Y, x_log_prob)\n",
        "auc = roc_auc_score(Y, x_log_prob)\n",
        "\n",
        "plt.plot(fpr,tpr,label=\"linear in-sample, auc=\"+str(auc))\n",
        "plt.title('VAE roc curve - training')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_kg_hide-input": true,
        "_uuid": "faa3c951606a479337af5eb7736ce4488ca4e4d3",
        "id": "U7E5rpDqRWMY"
      },
      "source": [
        "Above 0.96 in training set, pretty decent!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "6f187b6f99e8d4ce7707b85ae982b468d12b3f04",
        "id": "ZkSYra_PRWMZ"
      },
      "source": [
        "x_test_log_prob = reconstruction_log_prob(X_train_cleaned.values, reconstruct_samples_n)\n",
        "test_y = y_test\n",
        "\n",
        "fpr, tpr, thresh = roc_curve(test_y, -x_test_log_prob)\n",
        "auc = roc_auc_score(test_y, -x_test_log_prob)\n",
        "\n",
        "plt.plot(fpr,tpr,label=\"linear in-sample, auc=\"+str(auc))\n",
        "plt.title('VAE roc curve - test')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "_uuid": "b87ea1b3a35aa505f6887c0b441c73b0666573dd",
        "id": "81CtZRcZRWMZ"
      },
      "source": [
        "auc = roc_auc_score(test_y, clf.predict(data_test.drop(['Class'], axis = 1).values))\n",
        "\n",
        "plt.plot(fpr,tpr,label=\"linear in-sample, auc=\"+str(auc))\n",
        "plt.title('SVM roc curve - test')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_kg_hide-input": false,
        "_kg_hide-output": false,
        "_uuid": "1c954a9ab5fc4417632eba1faf14e80b2d842301",
        "id": "BS6zEldbRWMa"
      },
      "source": [
        "# Limitations \n",
        "* The VAE hidden layer design has room for improvement.\n",
        "* Hyperparameter tuning can be added."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMSloN_mqVLS"
      },
      "source": [
        "# Comparison with ADASYN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I0LdhZKrOt1"
      },
      "source": [
        "## PCA for Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLZC7nAbFEH4"
      },
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kszEhPGlqZEv"
      },
      "source": [
        "pca = PCA(n_components=2)\n",
        "X_train_vis = pca.fit_transform(X_train_cleaned, y_train)\n",
        "kwarg_params = {'linewidth': 1, 'edgecolor': 'black'}\n",
        "colors = ['#ef8a62' if v == 0 else '#67a9cf' if v == 1 else 'black' for v in y_train]\n",
        "plt.scatter(X_train_vis[:, 0], X_train_vis[:, 1], c=colors, **kwarg_params)\n",
        "plt.xlabel(\"PCA Variable 1\")\n",
        "plt.ylabel(\"PCA Variable 2\")\n",
        "sns.despine()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W9sdN_BrWr1"
      },
      "source": [
        "## ADASYN Up-sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTZwsft3q8Dg"
      },
      "source": [
        "X_train_resampled, y_train_resampled = ADASYN(ratio={0:74875, 1:10000}, n_neighbors=4).fit_sample(X_train_cleaned, y_train)\n",
        "# X_train_val_resampled, y_train_val_resampled = ADASYN(ratio={0:87353, 1:6000}, n_neighbors=3).fit_sample(X_train_val_cleaned, y_train_val)\n",
        "X_train_resampled_vis = pca.transform(X_train_resampled)\n",
        "colors = ['#ef8a62' if v == 0 else '#67a9cf' if v == 1 else 'black' for v in y_train_resampled]\n",
        "plt.scatter(X_train_resampled_vis[:, 0], X_train_resampled_vis[:, 1], c=colors, **kwarg_params)\n",
        "plt.xlabel(\"PCA Variable 1\")\n",
        "plt.ylabel(\"PCA Variable 2\")\n",
        "sns.despine()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPUa7GURJ32P"
      },
      "source": [
        "print(Counter(y_train))\n",
        "print(Counter(y_train_resampled))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VXhwCrprdqc"
      },
      "source": [
        "## Base Decision Tree Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udlu0gdaBsz8"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(max_depth=3).fit(X_train_cleaned,y_train)\n",
        "y_pred_train = dt.predict_proba(X_train_cleaned)[:,1]\n",
        "y_pred_val = dt.predict_proba(X_val_cleaned)[:,1]\n",
        "y_pred_train_val = dt.predict_proba(X_train_val_cleaned)[:,1]\n",
        "y_pred_test = dt.predict_proba(X_test_cleaned)[:,1]\n",
        "all_results.add_results(y_pred_train, y_pred_val, y_pred_train_val, y_pred_test, \"DT\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w1aNZhp-i7j"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt_resampled = DecisionTreeClassifier(max_depth=3).fit(X_train_resampled,y_train_resampled)\n",
        "y_pred_train = dt_resampled.predict_proba(X_train_cleaned.to_numpy())[:,1]\n",
        "y_pred_val = dt_resampled.predict_proba(X_val_cleaned.to_numpy())[:,1]\n",
        "y_pred_train_val = dt_resampled.predict_proba(X_train_val_cleaned.to_numpy())[:,1]\n",
        "y_pred_test = dt_resampled.predict_proba(X_test_cleaned.to_numpy())[:,1]\n",
        "all_results.add_results(y_pred_train, y_pred_val, y_pred_train_val, y_pred_test, \"DT-ADASYN\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zN2JdVECbZN"
      },
      "source": [
        "all_results.train_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrHoYRyeCeG3"
      },
      "source": [
        "all_results.val_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4vggka4CgnB"
      },
      "source": [
        "all_results.test_res"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}